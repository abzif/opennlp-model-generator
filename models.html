<!DOCTYPE html>


<!--
 | Generated by Apache Maven Doxia Site Renderer 1.11.1 from target/generated-site/markdown/models.md at 2025-03-27
 | Rendered using Apache Maven Fluido Skin 1.11.1
-->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="Apache Maven Doxia Site Renderer 1.11.1" />
    <title>opennlp-model-generator &#x2013; Pre-trained models</title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-1.11.1.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />
    <script src="./js/apache-maven-fluido-1.11.1.min.js"></script>
  </head>
  <body class="topBarDisabled">
    <div class="container-fluid">
      <header>
        <div id="banner">
          <div class="pull-left"><div id="bannerLeft"><h1>OpenNLP model generator</h1>
</div>
</div>
          <div class="pull-right"></div>
          <div class="clear"><hr/></div>
        </div>

        <div id="breadcrumbs">
          <ul class="breadcrumb">
        <li id="publishDate">Last Published: 2025-03-27<span class="divider">|</span>
</li>
          <li id="projectVersion">Version: ROLLING</li>
          </ul>
        </div>
      </header>
      <div class="row-fluid">
        <header id="leftColumn" class="span2">
          <nav class="well sidebar-nav">
  <ul class="nav nav-list">
   <li class="nav-header">Pages</li>
    <li><a href="index.html" title="Project description"><span class="none"></span>Project description</a></li>
    <li class="active"><a><span class="none"></span>Pre-trained models</a></li>
  </ul>
          </nav>
          <div class="well sidebar-nav">
            <div id="poweredBy">
              <div class="clear"></div>
              <div class="clear"></div>
              <div class="clear"></div>
<a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy"><img class="builtBy" alt="Built by Maven" src="./images/logos/maven-feather.png" /></a>
            </div>
          </div>
        </header>
        <main id="bodyColumn"  class="span10" >
<h1>Pre-trained models</h1><hr /><section>
<h2><a name="cs"></a>cs</h2>
<p>language code: <b>cs</b>, language name: <b>czech</b>, training sample size: <b>229k</b></p>
<ul>

<li>model file: <b><a href="models/cs-lucene/cs-sentence-detector.onlpm">cs-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-sentence-detector.txt">cs-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>85.47</b>%</li>
<li>model file: <b><a href="models/cs-lucene/cs-tokenizer.onlpm">cs-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-tokenizer.txt">cs-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.95</b>%</li>
<li>model file: <b><a href="models/cs-lucene/cs-pos-tagger.onlpm">cs-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-pos-tagger.txt">cs-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.94</b>%</li>
<li>model file: <b><a href="models/cs-lucene/cs-lemmatizer.onlpm">cs-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-lemmatizer.txt">cs-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>93.83</b>%</li>
</ul></section><section>
<h2><a name="da"></a>da</h2>
<p>language code: <b>da</b>, language name: <b>danish</b>, training sample size: <b>8k</b></p>
<ul>

<li>model file: <b><a href="models/da-lucene/da-sentence-detector.onlpm">da-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-sentence-detector.txt">da-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>87.73</b>%</li>
<li>model file: <b><a href="models/da-lucene/da-tokenizer.onlpm">da-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-tokenizer.txt">da-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.89</b>%</li>
<li>model file: <b><a href="models/da-lucene/da-pos-tagger.onlpm">da-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-pos-tagger.txt">da-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>96.24</b>%</li>
<li>model file: <b><a href="models/da-lucene/da-lemmatizer.onlpm">da-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-lemmatizer.txt">da-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>94.29</b>%</li>
</ul></section><section>
<h2><a name="de"></a>de</h2>
<p>language code: <b>de</b>, language name: <b>german</b>, training sample size: <b>124k</b></p>
<ul>

<li>model file: <b><a href="models/de-lucene/de-sentence-detector.onlpm">de-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-sentence-detector.txt">de-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>72.88</b>%</li>
<li>model file: <b><a href="models/de-lucene/de-tokenizer.onlpm">de-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-tokenizer.txt">de-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.93</b>%</li>
<li>model file: <b><a href="models/de-lucene/de-pos-tagger.onlpm">de-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-pos-tagger.txt">de-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.20</b>%</li>
<li>model file: <b><a href="models/de-lucene/de-lemmatizer.onlpm">de-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-lemmatizer.txt">de-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>85.02</b>%</li>
</ul></section><section>
<h2><a name="el"></a>el</h2>
<p>language code: <b>el</b>, language name: <b>greek</b>, training sample size: <b>7k</b></p>
<ul>

<li>model file: <b><a href="models/el-lucene/el-sentence-detector.onlpm">el-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-sentence-detector.txt">el-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>87.08</b>%</li>
<li>model file: <b><a href="models/el-lucene/el-tokenizer.onlpm">el-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-tokenizer.txt">el-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.97</b>%</li>
<li>model file: <b><a href="models/el-lucene/el-pos-tagger.onlpm">el-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-pos-tagger.txt">el-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.82</b>%</li>
<li>model file: <b><a href="models/el-lucene/el-lemmatizer.onlpm">el-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-lemmatizer.txt">el-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.83</b>%</li>
</ul></section><section>
<h2><a name="en"></a>en</h2>
<p>language code: <b>en</b>, language name: <b>english</b>, training sample size: <b>75k</b></p>
<ul>

<li>model file: <b><a href="models/en-lucene/en-sentence-detector.onlpm">en-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-sentence-detector.txt">en-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>75.93</b>%</li>
<li>model file: <b><a href="models/en-lucene/en-tokenizer.onlpm">en-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-tokenizer.txt">en-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.64</b>%</li>
<li>model file: <b><a href="models/en-lucene/en-pos-tagger.onlpm">en-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-pos-tagger.txt">en-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.72</b>%</li>
<li>model file: <b><a href="models/en-lucene/en-lemmatizer.onlpm">en-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-lemmatizer.txt">en-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>93.94</b>%</li>
</ul></section><section>
<h2><a name="es"></a>es</h2>
<p>language code: <b>es</b>, language name: <b>spanish</b>, training sample size: <b>61k</b></p>
<ul>

<li>model file: <b><a href="models/es-lucene/es-sentence-detector.onlpm">es-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-sentence-detector.txt">es-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>97.27</b>%</li>
<li>model file: <b><a href="models/es-lucene/es-tokenizer.onlpm">es-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-tokenizer.txt">es-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.92</b>%</li>
<li>model file: <b><a href="models/es-lucene/es-pos-tagger.onlpm">es-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-pos-tagger.txt">es-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>95.94</b>%</li>
<li>model file: <b><a href="models/es-lucene/es-lemmatizer.onlpm">es-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-lemmatizer.txt">es-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>95.86</b>%</li>
</ul></section><section>
<h2><a name="fi"></a>fi</h2>
<p>language code: <b>fi</b>, language name: <b>finnish</b>, training sample size: <b>59k</b></p>
<ul>

<li>model file: <b><a href="models/fi-lucene/fi-sentence-detector.onlpm">fi-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-sentence-detector.txt">fi-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>81.95</b>%</li>
<li>model file: <b><a href="models/fi-lucene/fi-tokenizer.onlpm">fi-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-tokenizer.txt">fi-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.76</b>%</li>
<li>model file: <b><a href="models/fi-lucene/fi-pos-tagger.onlpm">fi-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-pos-tagger.txt">fi-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>93.68</b>%</li>
<li>model file: <b><a href="models/fi-lucene/fi-lemmatizer.onlpm">fi-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-lemmatizer.txt">fi-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>93.76</b>%</li>
</ul></section><section>
<h2><a name="fr"></a>fr</h2>
<p>language code: <b>fr</b>, language name: <b>french</b>, training sample size: <b>42k</b></p>
<ul>

<li>model file: <b><a href="models/fr-lucene/fr-sentence-detector.onlpm">fr-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-sentence-detector.txt">fr-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>92.62</b>%</li>
<li>model file: <b><a href="models/fr-lucene/fr-tokenizer.onlpm">fr-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-tokenizer.txt">fr-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.94</b>%</li>
<li>model file: <b><a href="models/fr-lucene/fr-pos-tagger.onlpm">fr-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-pos-tagger.txt">fr-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.90</b>%</li>
<li>model file: <b><a href="models/fr-lucene/fr-lemmatizer.onlpm">fr-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-lemmatizer.txt">fr-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>95.10</b>%</li>
</ul></section><section>
<h2><a name="he"></a>he</h2>
<p>language code: <b>he</b>, language name: <b>hebrew</b>, training sample size: <b>11k</b></p>
<ul>

<li>model file: <b><a href="models/he-lucene/he-sentence-detector.onlpm">he-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-sentence-detector.txt">he-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>95.74</b>%</li>
<li>model file: <b><a href="models/he-lucene/he-tokenizer.onlpm">he-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-tokenizer.txt">he-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>92.59</b>%</li>
<li>model file: <b><a href="models/he-lucene/he-pos-tagger.onlpm">he-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-pos-tagger.txt">he-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>94.68</b>%</li>
<li>model file: <b><a href="models/he-lucene/he-lemmatizer.onlpm">he-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-lemmatizer.txt">he-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.93</b>%</li>
</ul></section><section>
<h2><a name="it"></a>it</h2>
<p>language code: <b>it</b>, language name: <b>italian</b>, training sample size: <b>72k</b></p>
<ul>

<li>model file: <b><a href="models/it-lucene/it-sentence-detector.onlpm">it-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-sentence-detector.txt">it-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>74.14</b>%</li>
<li>model file: <b><a href="models/it-lucene/it-tokenizer.onlpm">it-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-tokenizer.txt">it-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.79</b>%</li>
<li>model file: <b><a href="models/it-lucene/it-pos-tagger.onlpm">it-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-pos-tagger.txt">it-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.80</b>%</li>
<li>model file: <b><a href="models/it-lucene/it-lemmatizer.onlpm">it-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-lemmatizer.txt">it-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.07</b>%</li>
</ul></section><section>
<h2><a name="ja"></a>ja</h2>
<p>language code: <b>ja</b>, language name: <b>japanese</b>, training sample size: <b>18k</b></p>
<ul>

<li>model file: <b><a href="models/ja-lucene/ja-sentence-detector.onlpm">ja-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-sentence-detector.txt">ja-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>99.25</b>%</li>
<li>model file: <b><a href="models/ja-lucene/ja-tokenizer.onlpm">ja-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-tokenizer.txt">ja-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>81.43</b>%</li>
<li>model file: <b><a href="models/ja-lucene/ja-pos-tagger.onlpm">ja-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-pos-tagger.txt">ja-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>97.86</b>%</li>
<li>model file: <b><a href="models/ja-lucene/ja-lemmatizer.onlpm">ja-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-lemmatizer.txt">ja-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.65</b>%</li>
</ul></section><section>
<h2><a name="ko"></a>ko</h2>
<p>language code: <b>ko</b>, language name: <b>korean</b>, training sample size: <b>37k</b></p>
<ul>

<li>model file: <b><a href="models/ko-lucene/ko-sentence-detector.onlpm">ko-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-sentence-detector.txt">ko-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>95.14</b>%</li>
<li>model file: <b><a href="models/ko-lucene/ko-tokenizer.onlpm">ko-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-tokenizer.txt">ko-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.40</b>%</li>
<li>model file: <b><a href="models/ko-lucene/ko-pos-tagger.onlpm">ko-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-pos-tagger.txt">ko-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>89.85</b>%</li>
<li>model file: <b><a href="models/ko-lucene/ko-lemmatizer.onlpm">ko-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-lemmatizer.txt">ko-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>87.83</b>%</li>
</ul></section><section>
<h2><a name="no"></a>no</h2>
<p>language code: <b>no</b>, language name: <b>norwegian</b>, training sample size: <b>61k</b></p>
<ul>

<li>model file: <b><a href="models/no-lucene/no-sentence-detector.onlpm">no-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-sentence-detector.txt">no-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>84.07</b>%</li>
<li>model file: <b><a href="models/no-lucene/no-tokenizer.onlpm">no-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-tokenizer.txt">no-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.93</b>%</li>
<li>model file: <b><a href="models/no-lucene/no-pos-tagger.onlpm">no-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-pos-tagger.txt">no-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.05</b>%</li>
<li>model file: <b><a href="models/no-lucene/no-lemmatizer.onlpm">no-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-lemmatizer.txt">no-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>94.25</b>%</li>
</ul></section><section>
<h2><a name="pl"></a>pl</h2>
<p>language code: <b>pl</b>, language name: <b>polish</b>, training sample size: <b>72k</b></p>
<ul>

<li>model file: <b><a href="models/pl-lucene/pl-sentence-detector.onlpm">pl-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-sentence-detector.txt">pl-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>95.99</b>%</li>
<li>model file: <b><a href="models/pl-lucene/pl-tokenizer.onlpm">pl-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-tokenizer.txt">pl-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.86</b>%</li>
<li>model file: <b><a href="models/pl-lucene/pl-pos-tagger.onlpm">pl-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-pos-tagger.txt">pl-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.76</b>%</li>
<li>model file: <b><a href="models/pl-lucene/pl-lemmatizer.onlpm">pl-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-lemmatizer.txt">pl-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>91.82</b>%</li>
</ul></section><section>
<h2><a name="pt"></a>pt</h2>
<p>language code: <b>pt</b>, language name: <b>portuguese</b>, training sample size: <b>113k</b></p>
<ul>

<li>model file: <b><a href="models/pt-lucene/pt-sentence-detector.onlpm">pt-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-sentence-detector.txt">pt-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>74.60</b>%</li>
<li>model file: <b><a href="models/pt-lucene/pt-tokenizer.onlpm">pt-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-tokenizer.txt">pt-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.61</b>%</li>
<li>model file: <b><a href="models/pt-lucene/pt-pos-tagger.onlpm">pt-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-pos-tagger.txt">pt-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.36</b>%</li>
<li>model file: <b><a href="models/pt-lucene/pt-lemmatizer.onlpm">pt-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-lemmatizer.txt">pt-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>94.25</b>%</li>
</ul></section><section>
<h2><a name="ru"></a>ru</h2>
<p>language code: <b>ru</b>, language name: <b>russian</b>, training sample size: <b>186k</b></p>
<ul>

<li>model file: <b><a href="models/ru-lucene/ru-sentence-detector.onlpm">ru-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-sentence-detector.txt">ru-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>92.73</b>%</li>
<li>model file: <b><a href="models/ru-lucene/ru-tokenizer.onlpm">ru-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-tokenizer.txt">ru-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.87</b>%</li>
<li>model file: <b><a href="models/ru-lucene/ru-pos-tagger.onlpm">ru-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-pos-tagger.txt">ru-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>98.20</b>%</li>
<li>model file: <b><a href="models/ru-lucene/ru-lemmatizer.onlpm">ru-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-lemmatizer.txt">ru-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.11</b>%</li>
</ul></section><section>
<h2><a name="sv"></a>sv</h2>
<p>language code: <b>sv</b>, language name: <b>swedish</b>, training sample size: <b>20k</b></p>
<ul>

<li>model file: <b><a href="models/sv-lucene/sv-sentence-detector.onlpm">sv-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-sentence-detector.txt">sv-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>86.66</b>%</li>
<li>model file: <b><a href="models/sv-lucene/sv-tokenizer.onlpm">sv-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-tokenizer.txt">sv-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.97</b>%</li>
<li>model file: <b><a href="models/sv-lucene/sv-pos-tagger.onlpm">sv-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-pos-tagger.txt">sv-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>96.37</b>%</li>
<li>model file: <b><a href="models/sv-lucene/sv-lemmatizer.onlpm">sv-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-lemmatizer.txt">sv-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.42</b>%</li>
</ul></section><section>
<h2><a name="uk"></a>uk</h2>
<p>language code: <b>uk</b>, language name: <b>ukrainian</b>, training sample size: <b>17k</b></p>
<ul>

<li>model file: <b><a href="models/uk-lucene/uk-sentence-detector.onlpm">uk-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-sentence-detector.txt">uk-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>92.87</b>%</li>
<li>model file: <b><a href="models/uk-lucene/uk-tokenizer.onlpm">uk-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-tokenizer.txt">uk-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>99.92</b>%</li>
<li>model file: <b><a href="models/uk-lucene/uk-pos-tagger.onlpm">uk-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-pos-tagger.txt">uk-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>98.09</b>%</li>
<li>model file: <b><a href="models/uk-lucene/uk-lemmatizer.onlpm">uk-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-lemmatizer.txt">uk-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>96.97</b>%</li>
</ul></section><section>
<h2><a name="zh"></a>zh</h2>
<p>language code: <b>zh</b>, language name: <b>chinese</b>, training sample size: <b>23k</b></p>
<ul>

<li>model file: <b><a href="models/zh-lucene/zh-sentence-detector.onlpm">zh-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-sentence-detector.txt">zh-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>97.79</b>%</li>
<li>model file: <b><a href="models/zh-lucene/zh-tokenizer.onlpm">zh-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-tokenizer.txt">zh-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>95.77</b>%</li>
<li>model file: <b><a href="models/zh-lucene/zh-pos-tagger.onlpm">zh-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-pos-tagger.txt">zh-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>95.91</b>%</li>
<li>model file: <b><a href="models/zh-lucene/zh-lemmatizer.onlpm">zh-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-lemmatizer.txt">zh-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>99.50</b>%</li>
</ul></section>
        </main>
      </div>
    </div>
    <hr/>
    <footer>
      <div class="container-fluid">
        <div class="row-fluid">
            <p>&#169;      2025
</p>
        </div>
      </div>
    </footer>
<script>
	if(anchors) {
	  anchors.add();
	}
</script>
  </body>
</html>
